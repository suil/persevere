# Web Crawler
[1236. Web Crawler](https://leetcode.com/problems/web-crawler/)

Given a url startUrl and an interface HtmlParser, implement a web crawler to crawl all links that are under the same hostname as startUrl. 

# Key insights
- BFS traversal starting from the startUrl, exploring all links returned by the HTML parser
- Filters URLs by hostname to stay within the same domain
- Uses a visited Set to avoid processing the same URL multiple times

# Code
```javascript
/**
 * // This is the HtmlParser's API interface.
 * // You should not implement it, or speculate about its implementation
 * function HtmlParser() {
 *
 *		@param {string} url
 *     	@return {string[]}
 *     	this.getUrls = function(url) {
 *      	...
 *     	};
 * };
 */

/**
 * @param {string} startUrl
 * @param {HtmlParser} htmlParser
 * @return {string[]}
*/
var crawl = function(startUrl, htmlParser) {
    const hostname = new URL(startUrl).hostname;
    
    
    const visited = new Set([startUrl]);
    const queue = [startUrl];

    while (queue.length > 0) {
        const currUrl = queue.shift();
        const nextUrls = htmlParser.getUrls(currUrl);

        for (const nextUrl of nextUrls) {
            if (visited.has(nextUrl)) continue;
            if (hostname !== new URL(nextUrl).hostname) continue;

            visited.add(nextUrl);
            queue.push(nextUrl); 
        }
    }

    return [...visited];
};
```

# Complexity
**Time:** O(V + E) -- where V is the number of URLs visited and E is the total number of links
**Space:** O(V) -- for the visited set and queue
